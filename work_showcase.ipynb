{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b8cd16bd",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Table of Contents<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#Setup\" data-toc-modified-id=\"Setup-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>Setup</a></span><ul class=\"toc-item\"><li><span><a href=\"#Imports\" data-toc-modified-id=\"Imports-1.1\"><span class=\"toc-item-num\">1.1&nbsp;&nbsp;</span>Imports</a></span></li><li><span><a href=\"#Config\" data-toc-modified-id=\"Config-1.2\"><span class=\"toc-item-num\">1.2&nbsp;&nbsp;</span>Config</a></span></li><li><span><a href=\"#Setup\" data-toc-modified-id=\"Setup-1.3\"><span class=\"toc-item-num\">1.3&nbsp;&nbsp;</span>Setup</a></span></li></ul></li></ul></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb15a39c",
   "metadata": {},
   "source": [
    "This notebook presents key results of this project, walking through the steps from generating new MNIST digits to solving a photoacoustic tomography inverse problem on MNIST images. Key theoretical concepts are explained along each part."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3266e584",
   "metadata": {
    "id": "3266e584"
   },
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3379a4b",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3a73b370",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "3a73b370",
    "outputId": "545a2aab-2ceb-4724-b528-04461a0ca652"
   },
   "outputs": [],
   "source": [
    "import functools\n",
    "import torch\n",
    "import tqdm\n",
    "import os\n",
    "import sys\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torchvision.transforms as transforms\n",
    "from torchvision.datasets import MNIST, FashionMNIST, CIFAR10\n",
    "from torch.optim import Adam\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "# if run remotely: import utils from github repo\n",
    "IN_COLAB = 'google.colab' in sys.modules\n",
    "if IN_COLAB:\n",
    "    if os.path.isdir('./diffusion-for-photoacoustic/') == False:\n",
    "        ! git clone https://github.com/snigdhasaha7/diffusion-for-photoacoustic.git\n",
    "    sys.path.append('./diffusion-for-photoacoustic/')\n",
    "# if run locally: add parent path\n",
    "else:\n",
    "    parent_dir = os.path.dirname(os.getcwd())\n",
    "    sys.path.append(parent_dir)\n",
    "    \n",
    "import samplers\n",
    "from models import ScoreNet\n",
    "from sdes import Classic, VarianceExploding, VariancePreserving, SubVariancePreserving"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72d58811",
   "metadata": {
    "id": "72d58811"
   },
   "source": [
    "### Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7caa8eca",
   "metadata": {
    "id": "7caa8eca"
   },
   "outputs": [],
   "source": [
    "n_epochs = 50\n",
    "batch_size = 64\n",
    "lr = 1e-4\n",
    "device = 'cuda'         # ['cuda', 'cpu']\n",
    "dataset = 'CIFAR10'    # ['MNIST', 'FashionMNIST', 'CIFAR10']\n",
    "sde_type = 've'   # ['classic', 'vp', 've', 'subvp']\n",
    "sde_params = [0.01, 5]         # [classic: sigma][vp: b_min, b_max][ve|subve: s_min, s_max]\n",
    "gen_sampler = 'pc'     # ['em', 'pc', 'ode']\n",
    "denoise_sampler = 'pc' # ['em', 'pc']\n",
    "noise_std = .1\n",
    "training = True\n",
    "denoising = True"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7710d15e",
   "metadata": {},
   "source": [
    "### Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0f32ad14",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "# SDE\n",
    "if sde_type == 've':\n",
    "    SDE = VarianceExploding()\n",
    "    sigma_min, sigma_max = sde_params\n",
    "    params_str = '{}_{}'.format(*sde_params)\n",
    "    marginal_prob_std_fn = functools.partial(SDE.marginal_prob_std, sigma_min=sigma_min, sigma_max=sigma_max)\n",
    "    drift_coeff_fn = functools.partial(SDE.drift_coeff, sigma_min=sigma_min, sigma_max=sigma_max)\n",
    "    diffusion_coeff_fn = functools.partial(SDE.diffusion_coeff, sigma_min=sigma_min, sigma_max=sigma_max)\n",
    "elif sde_type == 'vp':\n",
    "    SDE = VariancePreserving()\n",
    "    beta_min, beta_max = sde_params\n",
    "    params_str = '{}_{}'.format(*sde_params)\n",
    "    marginal_prob_std_fn = functools.partial(SDE.marginal_prob_std, beta_min=beta_min, beta_max=beta_max)\n",
    "    drift_coeff_fn = functools.partial(SDE.drift_coeff, beta_min=beta_min, beta_max=beta_max)\n",
    "    diffusion_coeff_fn = functools.partial(SDE.diffusion_coeff, beta_min=beta_min, beta_max=beta_max)\n",
    "elif sde_type == 'subvp':\n",
    "    SDE = SubVariancePreserving()\n",
    "    beta_min, beta_max = sde_params\n",
    "    params_str = '{}_{}'.format(*sde_params)\n",
    "    marginal_prob_std_fn = functools.partial(SDE.marginal_prob_std, beta_min=beta_min, beta_max=beta_max)\n",
    "    drift_coeff_fn = functools.partial(SDE.drift_coeff, beta_min=beta_min, beta_max=beta_max)\n",
    "    diffusion_coeff_fn = functools.partial(SDE.diffusion_coeff, beta_min=beta_min, beta_max=beta_max)\n",
    "elif sde_type == 'classic':\n",
    "    SDE = Classic()\n",
    "    sigma = sde_params\n",
    "    params_str = '{}'.format(sde_params)\n",
    "    marginal_prob_std_fn = functools.partial(SDE.marginal_prob_std, sigma=sigma)\n",
    "    drift_coeff_fn = functools.partial(SDE.drift_coeff, sigma=sigma)\n",
    "    diffusion_coeff_fn = functools.partial(SDE.diffusion_coeff, sigma=sigma)\n",
    "    \n",
    "# sampler for generation\n",
    "if gen_sampler == 'em':\n",
    "    sampler = samplers.Euler_Maruyama_sampler\n",
    "elif gen_sampler == 'pc':\n",
    "    sampler = samplers.pc_sampler\n",
    "elif gen_sampler == 'ode':\n",
    "    sampler = samplers.ode_sampler\n",
    "\n",
    "# sampler for denoising\n",
    "if denoise_sampler == 'em':\n",
    "    denoiser = samplers.Euler_Maruyama_denoiser\n",
    "elif denoise_sampler == 'pc':\n",
    "    denoiser = samplers.pc_denoiser\n",
    "\n",
    "# training dataset\n",
    "if training:\n",
    "    if dataset == 'MNIST':\n",
    "        train_transforms = transforms.Compose([transforms.ToTensor()])\n",
    "        train_dataset = MNIST('.', train=True, transform=train_transforms, download=True);\n",
    "    elif dataset == 'FashionMNIST':\n",
    "        train_transforms = transforms.Compose([transforms.ToTensor()])\n",
    "        train_dataset = FashionMNIST('.', train=True, transform=train_transforms, download=True);\n",
    "    elif dataset == 'CIFAR10':\n",
    "        train_transforms = transforms.Compose(\n",
    "            [transforms.ToTensor(),\n",
    "             transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)),\n",
    "             transforms.Resize((28,28)),\n",
    "             transforms.Grayscale(num_output_channels=1)])\n",
    "        train_dataset = CIFAR10('.', train=True, transform=train_transforms, download=True);\n",
    "    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=4);\n",
    "\n",
    "# noisy dataset\n",
    "class AddGaussianNoise():\n",
    "    ''' Adds some Gaussian Noise ~ N(0, std^2 I) to an image\n",
    "    '''\n",
    "    # structure for custom transform follows pytorch source code\n",
    "    # https://pytorch.org/vision/stable/_modules/torchvision/transforms/transforms.html\n",
    "    def __init__(self, std=1.):\n",
    "        self.std = std\n",
    "\n",
    "    def __call__(self, image):\n",
    "        ''' Add noise, returns noisy image'''\n",
    "        noise = self.std * torch.randn_like(image)\n",
    "        return image + noise\n",
    "    def __repr__(self):\n",
    "        return f\"{self.__class__.__name__}()\"\n",
    "\n",
    "if denoising:\n",
    "    if dataset == 'MNIST':\n",
    "        test_transforms = transforms.Compose([transforms.ToTensor(), AddGaussianNoise(noise_std)])\n",
    "        test_dataset = MNIST('.', train=False, transform=test_transforms, download=True);\n",
    "    elif dataset == 'FashionMNIST':\n",
    "        test_transforms = transforms.Compose([transforms.ToTensor(), AddGaussianNoise(noise_std)])\n",
    "        test_dataset = FashionMNIST('.', train=False, transform=test_transforms, download=True);\n",
    "    elif dataset == 'CIFAR10':\n",
    "        test_transforms = transforms.Compose(\n",
    "            [transforms.ToTensor(),\n",
    "             transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)),\n",
    "             transforms.Resize((28,28)),\n",
    "             transforms.Grayscale(num_output_channels=1),\n",
    "             AddGaussianNoise(noise_std)])\n",
    "        test_dataset = CIFAR10('.', train=False, transform=test_transforms, download=True);\n",
    "    test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=True, num_workers=4);\n",
    "\n",
    "# model + optimizer\n",
    "score_model = torch.nn.DataParallel(ScoreNet(marginal_prob_std=marginal_prob_std_fn))\n",
    "score_model = score_model.to(device)\n",
    "optimizer = Adam(score_model.parameters(), lr=lr)\n",
    "\n",
    "# loss\n",
    "def loss_fn(model, x, marginal_prob_std, eps=1e-5):\n",
    "    random_t = torch.rand(x.shape[0], device=x.device) * (1. - eps) + eps  \n",
    "    z = torch.randn_like(x)\n",
    "    std = marginal_prob_std(random_t)\n",
    "    perturbed_x = x + z * std[:, None, None, None]\n",
    "    score = model(perturbed_x, random_t)\n",
    "    loss = torch.mean(torch.sum((score * std[:, None, None, None] + z)**2, dim=(1,2,3)))\n",
    "    return loss\n",
    "\n",
    "# checkpoint folder varies if on colab or local\n",
    "if IN_COLAB:\n",
    "    checkpoint_dir = './diffusion-for-photoacoustic/checkpoints/'\n",
    "else:\n",
    "    checkpoint_dir = './checkpoints/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "379a7752",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": false,
   "skip_h1_title": true,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
